# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ADlUOCajgKrKMeI6sNusKAfWWYDEBaJH
"""

!pip install streamlit -qq
import streamlit as st # Re-import after installation
import pandas as pd
import joblib
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# Page Configuration
st.set_page_config(
    page_title="Credit Card Default Prediction",
    page_icon="ðŸ’³",
    layout="centered"
)

st.title("ðŸ’³ Credit Card Default Prediction App")
st.markdown("Upload your test dataset to predict if a customer will default on their payment.")

# ==========================================
# 1. Dataset Upload
# ==========================================
uploaded_file = st.file_uploader("Upload your CSV file (must have same columns as training data)", type="csv")

if uploaded_file is not None:
    # Read the file
    data = pd.read_csv(uploaded_file)
    st.write("### Data Preview")
    st.dataframe(data.head())

    # ==========================================
    # 2. Model Selection
    # ==========================================
    st.sidebar.header("Model Configuration")
    model_option = st.sidebar.selectbox(
        "Choose a Classification Model",
        ["Logistic Regression", "Decision Tree", "kNN", "Naive Bayes", "Random Forest", "XGBoost"]
    )

    if st.sidebar.button("Run Prediction"):
        try:
            # Construct filename matches the saved format in train_models.py
            filename = f"model/{model_option.lower().replace(' ', '_')}.pkl"

            # Load Model
            model = joblib.load(filename)

            # Preprocessing: separate target if present, otherwise just use data
            # NOTE: We assume the user uploads data with the same feature columns
            if 'default.payment.next.month' in data.columns:
                X_test = data.drop(['ID', 'default.payment.next.month'], axis=1, errors='ignore')
                y_true = data['default.payment.next.month']
            elif 'target' in data.columns: # fallback if you renamed it
                X_test = data.drop('target', axis=1)
                y_true = data['target']
            else:
                X_test = data.drop('ID', axis=1, errors='ignore')
                y_true = None

            # Apply Scaling for specific models
            if model_option in ["Logistic Regression", "kNN"]:
                scaler = joblib.load("model/scaler.pkl")
                X_test = scaler.transform(X_test)

            # Prediction
            prediction = model.predict(X_test)

            # ==========================================
            # 3. Results & Evaluation
            # ==========================================
            st.write(f"### Results using {model_option}")

            if y_true is not None:
                # Calculate Metrics
                acc = accuracy_score(y_true, prediction)
                st.metric(label="Model Accuracy", value=f"{acc:.2%}")

                st.subheader("Classification Report")
                st.text(classification_report(y_true, prediction))

                st.subheader("Confusion Matrix")
                st.write(confusion_matrix(y_true, prediction))
            else:
                st.success("Predictions generated successfully!")

            # Append predictions to data and allow download
            results_df = data.copy()
            results_df['Prediction'] = prediction
            st.write("### Predictions Output")
            st.dataframe(results_df.head())

        except Exception as e:
            st.error(f"Error loading model or processing data: {e}")
            st.info("Ensure your 'model/' folder is in the same directory and contains all .pkl files.")